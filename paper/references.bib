@article{Mestetsky,
  author    = {Местецкий, Л. М.},
  title     = {Скелетизация многоугольной фигуры на основе обобщенной триангуляции Делоне},
  journal   = {Программирование},
  number    = {3},
  pages     = {16--31},
  year      = {1999}
}

@article{zykov,
  author    = {Зыков, В. П. and Местецкий, Л. М.},
  title     = {Пост-коррекция слабой расшифровки большими языковыми моделями в итерационном процессе распознавания рукописей},
  journal   = {Электронные библиотеки},
  volume    = {28},
  number    = {6},
  pages     = {1386--1414},
  year      = {2025}
}

@misc{InkSight,
  author = {Lee, C.-Y. and Wilber, M. and Sun, M. and Bui, T. and Yang, Y. and Wang, Y. and others},
  title  = {InkSight: Offline-to-Online Handwriting Conversion by Learning to Read and Write},
  year   = {2024},
  note   = {arXiv:2402.05804},
  howpublished = {arXiv preprint}
}

@inproceedings{ZykovMMRO2025,
  author    = {Зыков, В. П. and Местецкий, Л. М.},
  title     = {Итерационный подход к расшифровке и разметке рукописных дневников XIX века},
  booktitle = {22-я всероссийская конференция ММРО-2025},
  address   = {Муром, Россия},
  month     = sep,
  year      = {2025},
}

@inproceedings{MorozovMMRO2025,
  author    = {Морозов, И. Д. and Местецкий, Л. М.},
  title     = {Алгоритм поиска в рукописном тексте на основе штрихового представления},
  booktitle = {22-я всероссийская конференция ММРО-2025},
  address   = {Муром, Россия},
  month     = sep,
  year      = {2025}
}

@book{book,
  author    = {Местецкий, Л. М.},
  title     = {Непрерывная морфология бинарных изображений: фигуры, скелеты, циркуляры},
  publisher = {Физматлит},
  address   = {М.},
  year      = {2009}
}

@inproceedings{GanGCM,
  title     = {Structure-Aware Handwritten Text Recognition via Graph-Enhanced Cross-Modal  Mutual Learning},
  author    = {Gan, Ji and Zhou, Yupeng and Zhang, Yanming and Leng, Jiaxu and Gao, Xinbo},
  booktitle = {Proceedings of the Thirty-Fourth International Joint Conference on
               Artificial Intelligence, {IJCAI-25}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {James Kwok},
  pages     = {5154--5162},
  year      = {2025},
  month     = {8},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2025/574},
  url       = {https://doi.org/10.24963/ijcai.2025/574},
}

@misc{sharma2024,
      title={Graph Neural Network based Handwritten Trajectories Recognition}, 
      author={Anuj Sharma and Sukhdeep Singh and S Ratna},
      year={2024},
      eprint={2405.09247},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.09247}, 
}


@article{Marti2002,
author={Marti, U.-V.
and Bunke, H.},
title={The IAM-database: an English sentence database for offline handwriting recognition},
journal={International Journal on Document Analysis and Recognition},
year={2002},
month={Nov},
day={01},
volume={5},
number={1},
pages={39-46},
abstract={In this paper we describe a database that consists of handwritten English sentences. It is based on the Lancaster-Oslo/Bergen (LOB) corpus. This corpus is a collection of texts that comprise about one million word instances. The database includes 1,066 forms produced by approximately 400 different writers. A total of 82,227 word instances out of a vocabulary of 10,841 words occur in the collection. The database consists of full English sentences. It can serve as a basis for a variety of handwriting recognition tasks. However, it is expected that the database would be particularly useful for recognition tasks where linguistic knowledge beyond the lexicon level is used, because this knowledge can be automatically derived from the underlying corpus. The database also includes a few image-processing procedures for extracting the handwritten text from the forms and the segmentation of the text into lines and words.},
issn={1433-2833},
doi={10.1007/s100320200071},
url={https://doi.org/10.1007/s100320200071}
}

@article{READ2019,
author = {Simistira, Fotini and Saini, Rajkumar and Dobson, Derek and Morrey, Jon and Liwicki, Marcus},
year = {2019},
month = {03},
pages = {},
title = {ICDAR 2019 Historical Document Reading Challenge on Large Structured Chinese Family Records},
doi = {10.48550/arXiv.1903.03341}
}

@inproceedings{CTC2006,
author = {Graves, Alex and Fernández, Santiago and Gomez, Faustino and Schmidhuber, Jürgen},
year = {2006},
month = {01},
pages = {369-376},
title = {Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural 'networks},
volume = {2006},
journal = {ICML 2006 - Proceedings of the 23rd International Conference on Machine Learning},
doi = {10.1145/1143844.1143891}
}

@article{CRNN2015,
author = {Shi, Baoguang and Bai, Xiang and Yao, Cong},
year = {2015},
month = {07},
pages = {},
title = {An End-to-End Trainable Neural Network for Image-Based Sequence Recognition and Its Application to Scene Text Recognition},
volume = {PP},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
doi = {10.1109/TPAMI.2016.2646371}
}

@article{Li_Lv_Chen_Cui_Lu_Florencio_Zhang_Li_Wei_2023, 
title={TrOCR: Transformer-Based Optical Character Recognition with Pre-trained Models}, 
volume={37}, 
url={https://ojs.aaai.org/index.php/AAAI/article/view/26538}, 
DOI={10.1609/aaai.v37i11.26538}, 
abstractNote={Text recognition is a long-standing research problem for document digitalization. Existing approaches are usually built based on CNN for image understanding and RNN for char-level text generation. In addition, another language model is usually needed to improve the overall accuracy as a post-processing step. In this paper, we propose an end-to-end text recognition approach with pre-trained image Transformer and text Transformer models, namely TrOCR, which leverages the Transformer architecture for both image understanding and wordpiece-level text generation. The TrOCR model is simple but effective, and can be pre-trained with large-scale synthetic data and fine-tuned with human-labeled datasets. Experiments show that the TrOCR model outperforms the current state-of-the-art models on the printed, handwritten and scene text recognition tasks. The TrOCR models and code are publicly available at https://aka.ms/trocr.}, 
number={11}, 
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
author={Li, Minghao and Lv, Tengchao and Chen, Jingye and Cui, Lei and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Li, Zhoujun and Wei, Furu}, 
year={2023}, 
month={Jun.}, 
pages={13094-13102} }

@article{Li_2025,
   title={HTR-VT: Handwritten text recognition with vision transformer},
   volume={158},
   ISSN={0031-3203},
   url={http://dx.doi.org/10.1016/j.patcog.2024.110967},
   DOI={10.1016/j.patcog.2024.110967},
   journal={Pattern Recognition},
   publisher={Elsevier BV},
   author={Li, Yuting and Chen, Dexiong and Tang, Tinglong and Shen, Xi},
   year={2025},
   month=feb, pages={110967} }

@article{FINet2025,
author = {Zhu, Yuanping and Li, Shengnan and Wang, Hui and Wei, Feilong},
year = {2025},
month = {01},
pages = {110949},
title = {FINet: Handwriting trajectory reconstruction of Chinese characters based on the font imitate network},
volume = {157},
journal = {Pattern Recognition},
doi = {10.1016/j.patcog.2024.110949}
}

@article{Kryzhanovskaya2020,
author = {Kryzhanovskaya, Svetlana and Arseev, Sergey and Mestetskiy, Leonid},
year = {2020},
month = {12},
pages = {paper27-1},
title = {Pen Trace Reconstruction with Skeleton Representation of a Handwritten Text Image},
journal = {Proceedings of the 30th International Conference on Computer Graphics and Machine Vision (GraphiCon 2020). Part 2},
doi = {10.51130/graphicon-2020-2-3-27}
}

@inproceedings{Sharma2013,
author = {Sharma, Anuj},
year = {2013},
month = {12},
pages = {},
title = {Recovery of Drawing order in Handwritten Digit Images},
journal = {2013 IEEE 2nd International Conference on Image Information Processing, IEEE ICIIP 2013},
doi = {10.1109/ICIIP.2013.6707630}
}

@article{Sharma2015,
author = {Sharma, Anuj},
year = {2015},
month = {01},
pages = {133-142},
title = {A Combined Static and Dynamic Feature Extraction Technique to recognize handwritten digits},
volume = {2},
journal = {Vietnam Journal of Mathematics},
doi = {10.1007/s40595-014-0038-1}
}

@article{Sharma2017,
author = {Singh, Sukhdeep and Sharma, Anuj and Chhabra, Indu},
year = {2017},
month = {03},
pages = {},
title = {A dominant points-based feature extraction approach to recognize online handwritten strokes},
volume = {20},
journal = {International Journal on Document Analysis and Recognition (IJDAR)},
doi = {10.1007/s10032-016-0279-x}
}

@INPROCEEDINGS{DiagGCN2024,
  author={Wang, Hao-Zhe and Zhang, Yan-Ming and Yin, Fei and Huang, Lin-Lin},
  booktitle={2024 IEEE 8th International Conference on Vision, Image and Signal Processing (ICVISP)}, 
  title={DiagGCN: An End-to-end Framework for Online Handwritten Diagram Recognition}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  keywords={Handwriting recognition;Image recognition;Human-machine systems;Education;Symbols;Writing;Signal processing;Feature extraction;Graph neural networks;online handwriting analysis;handwritten dia-gram recognition;sketch recognition},
  doi={10.1109/ICVISP64524.2024.10959153}}

@InProceedings{Khanfir_2024_WACV,
    author    = {Khanfir, Yessine and Dhiaf, Marwa and Ghodhbani, Emna and Rouhou, Ahmed Cheikh and Kessentini, Yousri},
    title     = {Graph Neural Networks for End-to-End Information Extraction From Handwritten Documents},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {January},
    year      = {2024},
    pages     = {504-512}
}

@misc{yuan2025onlinehandwrittensignatureverification,
      title={Online Handwritten Signature Verification Based on Temporal-Spatial Graph Attention Transformer}, 
      author={Hai-jie Yuan and Heng Zhang and Fei Yin},
      year={2025},
      eprint={2510.19321},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.19321}, 
}

@article{Feoktistov2024,
author = {Feoktistov, Dmitrii and Mestetskiy, Leonid},
year = {2024},
month = {12},
pages = {49-54},
title = {Keywords spotting in Russian handwritten documents based on strokes segmentation},
volume = {XLVIII-2/W5-2024},
journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
doi = {10.5194/isprs-archives-XLVIII-2-W5-2024-49-2024}
}

@misc{luo2026entropyawarestructuralalignmentzeroshot,
      title={Entropy-Aware Structural Alignment for Zero-Shot Handwritten Chinese Character Recognition}, 
      author={Qiuming Luo and Tao Zeng and Feng Li and Heming Liu and Rui Mao and Chang Kong},
      year={2026},
      eprint={2602.03913},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2602.03913}, 
}

@article{10.1007/s10994-023-06450-6,
author = {Yu, Haiyang and Chen, Jingye and Li, Bin and Xue, Xiangyang},
title = {Chinese character recognition with radical-structured stroke trees},
year = {2023},
issue_date = {Jun 2024},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {113},
number = {6},
issn = {0885-6125},
url = {https://doi.org/10.1007/s10994-023-06450-6},
doi = {10.1007/s10994-023-06450-6},
abstract = {The flourishing blossom of deep learning has witnessed the rapid development of Chinese character recognition. However, it remains a great challenge that the characters for testing may have different distributions from those of the training dataset. Existing methods based on a single-level representation (character-level, radical-level, or stroke-level) may be either too sensitive to distribution changes (e.g., induced by blurring, occlusion, and zero-shot problems) or too tolerant to one-to-many ambiguities. In this paper, we represent each Chinese character as a stroke tree, which is organized according to its radical structures, to fully exploit the merits of both radical and stroke levels in a decent way. We propose a two-stage decomposition framework, where a Feature-to-Radical Decoder decomposes each character into a radical sequence and a Radical-to-Stroke Decoder further decomposes each radical into the corresponding stroke sequence. The generated radical and stroke sequences are encoded as a radical-structured stroke tree (RSST), which is fed into a Tree-to-Character Translator based on the proposed Weighted Edit Distance to match the closest candidate character in the RSST lexicon. We have conducted extensive experiments on various datasets, such as handwritten, printed artistic, scene character datasets. The experimental results demonstrate that the proposed method outperforms the state-of-the-art single-level methods by increasing margins as the distribution difference becomes more severe in the blurring, occlusion, and zero-shot scenarios. For example, compared with the previous SOTA method, our method improve performance by 1.74–7.58\% in the handwritten character zero-shot settings.},
journal = {Mach. Learn.},
month = dec,
pages = {3807–3827},
numpages = {21},
keywords = {Chinese character recognition, Radical-structured stroke trees, Chinese character decomposition, Weighted edit distance}
}

@article{Liu2023,
author = {Liu, Jing-Yu and Zhang, Yan-Ming and Yin, Fei and Liu, Cheng-Lin},
year = {2023},
month = {11},
pages = {110131},
title = {Transformer-based stroke relation encoding for online handwriting and sketches},
volume = {148},
journal = {Pattern Recognition},
doi = {10.1016/j.patcog.2023.110131}
}

@article{DyGAT2023,
author = {Yang, Yu-Ting and Zhang, Yan-Ming and Yun, Xiao-Long and Yin, Fei and Liu, Cheng-Lin},
year = {2023},
month = {04},
pages = {109564},
title = {DyGAT: Dynamic Stroke Classification of Online Handwritten Documents and Sketches},
volume = {141},
journal = {Pattern Recognition},
doi = {10.1016/j.patcog.2023.109564}
}

@InProceedings{10.1007/978-3-032-04624-6_24,
author="Luo, Qiuming
and Zeng, Tao
and Wei, Xuan
and Kong, Chang",
editor="Yin, Xu-Cheng
and Karatzas, Dimosthenis
and Lopresti, Daniel",
title="Radical Sequence Encoding with Fine-Tuned CLIP for Handwritten Chinese Character Recognition",
booktitle="Document Analysis and Recognition -- ICDAR 2025",
year="2026",
publisher="Springer Nature Switzerland",
address="Cham",
pages="408--424",
abstract="Chinese characters are logographic in nature and possess complex compositional structures, making their recognition inherently challenging, particularly in handwritten form. Zero-shot recognition of Chinese characters further exacerbates this challenge. By leveraging the inherent structural properties of Chinese characters, it is possible to extract fine-grained structural information essential for effective recognition. Most current recognition methods rely on hard-coded representations of characters or radicals, overlooking the inherent flexibility and compositional similarity among them. This paper presents a novel radical encoding and information extraction module. The radical encoding module is built upon fine-tuning the CLIP model to learn continuous representations of radicals and their structural relationships. The information extraction module parses the radical sequence into a tree structure and extracts information to generate embeddings. We also evaluate the similarity between image features and embeddings. Our approach can also be used for zero-shot learning recognition tasks demonstrating superior performance compared to existing methods. To the best of our knowledge, this is the first work to fine-tune CLIP for continuous radical encoding while simultaneously integrating radical sequence information for enhanced recognition. Experimental results on zero-shot handwritten Chinese character recognition show that our method outperforms existing approaches, highlighting the effectiveness of the proposed methodology.",
isbn="978-3-032-04624-6"
}

@misc{yu2023chinesetextrecognitionpretrained,
      title={Chinese Text Recognition with A Pre-Trained CLIP-Like Model Through Image-IDS Aligning}, 
      author={Haiyang Yu and Xiaocong Wang and Bin Li and Xiangyang Xue},
      year={2023},
      eprint={2309.01083},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2309.01083}, 
}

@inproceedings{10.1145/3503161.3547827,
author = {Zu, Xinyan and Yu, Haiyang and Li, Bin and Xue, Xiangyang},
title = {Chinese Character Recognition with Augmented Character Profile Matching},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3547827},
doi = {10.1145/3503161.3547827},
abstract = {Chinese character recognition (CCR) has drawn continuous research interest due to its wide applications. After decades of study, there still exist several challenges,e.g., different characters with similar appearance and the one-to-many problem. There is no unified solution to the above challenges as previous methods tend to address these problems separately. In this paper, we propose a Chinese character recognition method named Augmented Character Profile Matching (ACPM), which utilizes a collection of character knowledge from three decomposition levels to recognize Chinese characters. Specifically, the feature maps of each character image are utilized as the character-level knowledge. In addition, we introduce a radical-stroke counting module (RSC) to help produce augmented character profiles, including the number of radicals, the number of strokes, and the total length of strokes, which characterize the character more comprehensively. The feature maps of the character image and the outputs of the RSC module are collected to constitute a character profile for selecting the closest candidate character through joint matching. The experimental results show that the proposed method outperforms the state-of-the-art methods on both the ICDAR 2013 and CTW datasets by 0.35\% and 2.23\%, respectively. Moreover, it also clearly outperforms the compared methods in the zero-shot settings. Code is available at https://github.com/FudanVI/FudanOCR/tree/main/character-profile-matching.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {6094–6102},
numpages = {9},
keywords = {OCR, character profile matching, chinese character knowledge, chinese character recognition},
location = {Lisboa, Portugal},
series = {MM '22}
}

@misc{chen2021zeroshotchinesecharacterrecognition,
      title={Zero-Shot Chinese Character Recognition with Stroke-Level Decomposition}, 
      author={Jingye Chen and Bin Li and Xiangyang Xue},
      year={2021},
      eprint={2106.11613},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2106.11613}, 
}

@article{HDE2020,
author = {Cao, Zhong and Lu, Jiang and Cui, Sen and Zhang, Changshui},
year = {2020},
month = {06},
pages = {107488},
title = {Zero-Shot Handwritten Chinese Character Recognition with Hierarchical Decomposition Embedding},
volume = {107},
journal = {Pattern Recognition},
doi = {10.1016/j.patcog.2020.107488}
}

@misc{hamilton2018inductiverepresentationlearninglarge,
      title={Inductive Representation Learning on Large Graphs}, 
      author={William L. Hamilton and Rex Ying and Jure Leskovec},
      year={2018},
      eprint={1706.02216},
      archivePrefix={arXiv},
      primaryClass={cs.SI},
      url={https://arxiv.org/abs/1706.02216}, 
}

@article{Mestetskiy2024,
    author = {Mestetskiy, L.},
    year = {2025},
    month = {04},
    pages = {1185-1191},
    title = {Stroke Segmentation of Handwritten Text Based on Medial Representation},
    volume = {34},
    journal = {Pattern Recognition and Image Analysis},
    doi = {10.1134/S1054661824701256}
}